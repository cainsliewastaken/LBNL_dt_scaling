# Training Configuration for ViT 2D Turbulence Model

# Data parameters
data:
  time_step: 1e-2
  spinup: 7500
  N_test: 5000
  N_train: 10000
  Nlat: 256
  Nlon: 256
  T_train_final: 0.6
  T_test_final: 1.0

# Training parameters
training:
  epochs: 100
  starting_epoch: 0
  learning_rate: 1e-3
  batch_size: 4
  batch_size_test: 100

# Model architecture parameters
model:
  # Architecture type: 'vit' or 'fno'
  architecture: 'vit'
  
  # ViT parameters (used when architecture='vit')
  img_size: [256, 256]
  patch_size: [8,8]
  in_chans: 1
  out_chans: 1
  embed_dim: 64
  depth: 5
  num_heads: 8
  head_dim: 64
  mlp_dim_multiplier: 4
  
  # FNO parameters (used when architecture='fno')
  modes: 64
  width: 128

# Optimizer and scheduler parameters
optimizer:
  type: "Adam"
  fused: true
  scheduler_type: "ExponentialLR"
  scheduler_gamma: 0.975
  # Alternative scheduler options:
  # scheduler_type: "CosineAnnealingWarmRestarts"
  # scheduler_T_0: 50
  # scheduler_eta_min: 1e-6

# Loss function parameters
loss:
  type: "MSELoss"
  reduction: "mean"

# Paths
paths:
  path_outputs: "/global/homes/c/cainslie/LBNL_dt_scaling/model_chkpts_scratch/"
  net_name: "ViT_Euler_multistep_dt0.01"
  # Checkpoint loading (optional - leave empty to start from scratch)
  load_checkpoint: ""

# Training options
options:
  save_every_n_epochs: 10
  use_distributed: true
  backend: "nccl"

# Weights & Biases configuration
wandb:
  enabled: true
  project: "LBNL_dt_scaling"
  entity: null  # Set to your wandb username/team if needed
  name: null  # Auto-generated if null
  tags: ["turbulence", "vit", "fno", "pde"]
  notes: "Training 2D turbulence model"
  log_model: true
  log_samples: true
  log_freq: 1  # Log every N epochs
  log_gradients: false
  log_parameters: true
